# API Configuration
# Replace with your actual API base URL and Key
# For local LLMs (like Parallax, vLLM, Ollama), this is often http://localhost:8000/v1 or similar
LLM_BASE_URL="http://localhost:8888/v1"
LLM_API_KEY="parallax"

# LLM provider: OPENAI | PARALLAX
LLM_MODE="OPENAI"

# Model Name
# Ensure this matches the model loaded in your backend
MODEL_NAME="Qwen/Qwen2.5-32B-Instruct-GGUF"
